{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Machine Translation\n",
    "\n",
    "In this work you need to implement any Seq2seq architecture to train neural German-Ukrainian translator.\n",
    "\n",
    "Mostly copy of [practical-pytorch](https://github.com/spro/practical-pytorch/blob/master/seq2seq-translation/seq2seq-translation.ipynb) tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from tokenize_uk import tokenize_words\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Managing **environment** (CPU or GPU) is not simple in pytorch. You need to explicitly select environment for all tensors in your model. Use this constant to define GPU usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "USE_CUDA = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "We will use open source sentence pairs from [tatoeba.org](https://tatoeba.org/eng/downloads). Download [sentences archive](http://downloads.tatoeba.org/exports/sentences.tar.bz2) and extract it into `./data/part3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DATA_DIR=./../data/part3/\n"
     ]
    }
   ],
   "source": [
    "%env DATA_DIR = ./../data/part3/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-07-15 19:10:01--  https://downloads.tatoeba.org/exports/sentences.tar.bz2\n",
      "Resolving downloads.tatoeba.org (downloads.tatoeba.org)... 94.130.77.194\n",
      "Connecting to downloads.tatoeba.org (downloads.tatoeba.org)|94.130.77.194|:443... connected.\n",
      "HTTP request sent, awaiting response... ^C\n",
      "x sentences.csv\n"
     ]
    }
   ],
   "source": [
    "!wget https://downloads.tatoeba.org/exports/sentences.tar.bz2 -P $DATA_DIR\n",
    "!tar xvjC $DATA_DIR -f $DATA_DIR/sentences.tar.bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-07-07 21:26:36--  https://downloads.tatoeba.org/exports/links.tar.bz2\n",
      "Resolving downloads.tatoeba.org (downloads.tatoeba.org)... 94.130.77.194\n",
      "Connecting to downloads.tatoeba.org (downloads.tatoeba.org)|94.130.77.194|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 72991002 (70M) [application/octet-stream]\n",
      "Saving to: ‘./../data/part3/links.tar.bz2.2’\n",
      "\n",
      "links.tar.bz2.2     100%[===================>]  69.61M  3.19MB/s    in 24s     \n",
      "\n",
      "2018-07-07 21:27:00 (2.90 MB/s) - ‘./../data/part3/links.tar.bz2.2’ saved [72991002/72991002]\n",
      "\n",
      "x links.csv\n"
     ]
    }
   ],
   "source": [
    "!wget https://downloads.tatoeba.org/exports/links.tar.bz2 -P $DATA_DIR\n",
    "!tar xvjC $DATA_DIR -f $DATA_DIR/links.tar.bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = './../data/part3/'\n",
    "sentences = pd.read_csv(os.path.join(data_dir, 'sentences.csv'), names=['id', 'lang', 'text'], header=None, delimiter='\\t')\n",
    "links = pd.read_csv(os.path.join(data_dir, 'links.csv'), names=['sent_id', 'tran_id'], header=None, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose any languages you want to train translator for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textukr</th>\n",
       "      <th>textdeu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Він наказав мені негайно вийти з кімнати.</td>\n",
       "      <td>Er befahl mir, den Raum umgehend zu verlassen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>У всесвіті багато галактик.</td>\n",
       "      <td>Es gibt viele Galaxien im Universum.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>У Всесвіті є багато галактик.</td>\n",
       "      <td>Es gibt viele Galaxien im Universum.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Вона приймає душ щоранку.</td>\n",
       "      <td>Sie nimmt jeden Morgen eine Dusche.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Вона приймає душ щоранку.</td>\n",
       "      <td>Sie duscht jeden Morgen.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     textukr  \\\n",
       "0  Він наказав мені негайно вийти з кімнати.   \n",
       "1                У всесвіті багато галактик.   \n",
       "2              У Всесвіті є багато галактик.   \n",
       "3                  Вона приймає душ щоранку.   \n",
       "4                  Вона приймає душ щоранку.   \n",
       "\n",
       "                                          textdeu  \n",
       "0  Er befahl mir, den Raum umgehend zu verlassen.  \n",
       "1            Es gibt viele Galaxien im Universum.  \n",
       "2            Es gibt viele Galaxien im Universum.  \n",
       "3             Sie nimmt jeden Morgen eine Dusche.  \n",
       "4                        Sie duscht jeden Morgen.  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_lang = 'ukr'\n",
    "target_lang = 'deu'\n",
    "\n",
    "source_sentences = sentences[sentences.lang == source_lang]\n",
    "source_sentences = source_sentences.merge(links, left_on='id', right_on='sent_id')\n",
    "target_sentences = sentences[sentences.lang == target_lang]\n",
    "\n",
    "bilang_sentences = source_sentences.merge(target_sentences, left_on='tran_id', \n",
    "                                          right_on='id', \n",
    "                                          suffixes=[source_lang, target_lang])\n",
    "bilang_sentences = bilang_sentences[['text'+source_lang, 'text'+target_lang]]\n",
    "\n",
    "file_name = os.path.join(data_dir, '{source}-{target}.csv'.format(source=source_lang, target=target_lang)) \n",
    "bilang_sentences.to_csv(file_name, index=False, sep='\\t')\n",
    "\n",
    "bilang_sentences.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing words\n",
    "\n",
    "We'll need a unique index per word to use as the inputs and targets of the networks later. To keep track of all this we will use a helper class called `Vocab` which has word → index (word2index) and index → word (index2word) dictionaries, as well as a count of each word word2count to use to later replace rare words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "UNK_token = 2\n",
    "PAD_token = 3\n",
    "\n",
    "class Vocab:\n",
    "    def __init__(self):\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\", 2: \"UNK\", 3: \"PAD\"}\n",
    "        self.word2index = {v: k for k, v in self.index2word.items()}\n",
    "      \n",
    "    def index_words(self, words):\n",
    "        for word in words:\n",
    "            self.index_word(word)\n",
    "\n",
    "    def index_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            n_words = len(self)\n",
    "            self.word2index[word] = n_words\n",
    "            self.index2word[n_words] = word\n",
    "            \n",
    "    def __len__(self):\n",
    "        assert len(self.index2word) == len(self.word2index)\n",
    "        return len(self.index2word)\n",
    "    \n",
    "    def restore_words(self, indices):\n",
    "        return ' '.join([self.index2word[i] for i in indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_string(s):\n",
    "    s = s.lower().strip()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read the data file we will split the file into lines, and then split lines into pairs. Define tokenizers for you languages to split sentences on words.\n",
    "\n",
    "Since there are a lot of example sentences and we want to train something quickly, we'll trim the data set to only relatively short and simple sentences. Here the maximum length is 6 words (that includes punctuation) and we're filtering to sentences that translate to the form \"I am\" or \"He is\" etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0108af73f914731b02362bc1ae7f1c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12833"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_tokenizer = tokenize_words\n",
    "target_tokenizer = nltk.tokenize.WordPunctTokenizer().tokenize\n",
    "\n",
    "MAX_LENGTH = 8\n",
    "\n",
    "def read_langs(source_lang, source_tokenizer, target_lang, target_tokenizer, input_file):\n",
    "    corpora = pd.read_csv(input_file, delimiter='\\t')\n",
    "    \n",
    "    source_vocab = Vocab()\n",
    "    target_vocab = Vocab()\n",
    "    \n",
    "    source_corpora = []\n",
    "    target_corpora = []\n",
    "    for i, row in tqdm(corpora.iterrows()):\n",
    "        source_sent = row['text'+source_lang].lower().strip()\n",
    "        target_sent = row['text'+target_lang].lower().strip()\n",
    "        \n",
    "        source_tokenized = source_tokenizer(source_sent)\n",
    "        target_tokenized = target_tokenizer(target_sent)\n",
    "        if len(source_tokenized) > MAX_LENGTH or \\\n",
    "           len(target_tokenized) > MAX_LENGTH:\n",
    "            continue\n",
    "        \n",
    "        source_corpora.append(source_tokenized)\n",
    "        target_corpora.append(target_tokenized)\n",
    "        \n",
    "        target_vocab.index_words(target_tokenized)\n",
    "        source_vocab.index_words(source_tokenized)\n",
    "    return source_vocab, target_vocab, list(zip(source_corpora, target_corpora))\n",
    "\n",
    "source_vocab, target_vocab, corpora = read_langs(source_lang, source_tokenizer, target_lang, target_tokenizer, file_name)\n",
    "len(corpora)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turning training data into Tensors\n",
    "To train we need to turn the sentences into something the neural network can understand, which of course means numbers. Each sentence will be split into words and turned into a Tensor, where each word is replaced with the index (from the Lang indexes made earlier). While creating these tensors we will also append the EOS token to signal that the sentence is over.\n",
    "\n",
    "A Tensor is a multi-dimensional array of numbers, defined with some type e.g. FloatTensor or LongTensor. In this case we'll be using LongTensor to represent an array of integer indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_SEQ_LENGTH = MAX_LENGTH+2 # 2 for EOS_token and SOS_token\n",
    "\n",
    "def indexes_from_sentence(vocab, sentence):\n",
    "    return [vocab.word2index[word] for word in sentence]\n",
    "\n",
    "def tensor_from_sentence(lang, sentence):\n",
    "    indexes = indexes_from_sentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    indexes.insert(0, SOS_token)\n",
    "    # we need to have all sequences the same length to process them in batches\n",
    "    if len(indexes) < MAX_SEQ_LENGTH:\n",
    "        indexes += [PAD_token]*(MAX_SEQ_LENGTH-len(indexes))\n",
    "    tensor = torch.LongTensor(indexes)\n",
    "    if USE_CUDA: var = tensor.cuda()\n",
    "    return tensor\n",
    "\n",
    "def tensors_from_pair(source_sent, target_sent):\n",
    "    source_tensor = tensor_from_sentence(source_vocab, source_sent).unsqueeze(1)\n",
    "    target_tensor = tensor_from_sentence(target_vocab, target_sent).unsqueeze(1)\n",
    "    \n",
    "    return (source_tensor, target_tensor)\n",
    "\n",
    "tensors = []\n",
    "for source_sent, target_sent in corpora:\n",
    "    tensors.append(tensors_from_pair(source_sent, target_sent))\n",
    "    \n",
    "x, y = zip(*tensors)\n",
    "x = torch.transpose(torch.cat(x, dim=-1), 1, 0)\n",
    "y = torch.transpose(torch.cat(y, dim=-1), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder\n",
    "\n",
    "The encoder of a seq2seq network is a RNN that outputs some value for every word from the input sentence. For every input word the encoder outputs a vector and a hidden state, and uses the hidden state for the next input word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, n_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
    "        self.embedding\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers=n_layers, batch_first=True, bidirectional=True)\n",
    "        \n",
    "    def forward(self, word_inputs, hidden): # word_inputs: (batch_size, seq_length), h: (h_or_c, layer_n_direction, batch, seq_length)\n",
    "        # Note: we run this all at once (over the whole input sequence)\n",
    "        seq_len = len(word_inputs)\n",
    "        \n",
    "        # embedded (batch_size, seq_length, hidden_size)\n",
    "        embedded = self.embedding(word_inputs) \n",
    "        # output (batch_size, seq_length, hidden_size*directions)\n",
    "        # hidden (h: (batch_size, num_layers*directions, hidden_size),\n",
    "        #         c: (batch_size, num_layers*directions, hidden_size))\n",
    "        output, hidden = self.lstm(embedded, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batches):\n",
    "        hidden = torch.zeros(2, self.n_layers*2, batches, self.hidden_size)\n",
    "        if USE_CUDA: hidden = hidden.cuda()\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, n_layers=1):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers=n_layers, batch_first=True, bidirectional=False)\n",
    "        \n",
    "    def forward(self, word_inputs, hidden):\n",
    "        # Note: we run this one by one\n",
    "        # embedded (batch_size, 1, hidden_size)\n",
    "        embedded = self.embedding(word_inputs).unsqueeze_(1)\n",
    "        output, hidden = self.lstm(embedded, hidden)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure the Encoder and Decoder model are working (and working together) we'll do a quick test with fake word inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderRNN(\n",
      "  (embedding): Embedding(10, 10)\n",
      "  (lstm): LSTM(10, 10, num_layers=2, batch_first=True, bidirectional=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 20])"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_test = EncoderRNN(10, 10, 2)\n",
    "print(encoder_test)\n",
    "\n",
    "encoder_hidden = encoder_test.init_hidden(1)\n",
    "word_input = torch.LongTensor([[1, 2, 3]])\n",
    "\n",
    "if USE_CUDA:\n",
    "    encoder_test.cuda()\n",
    "    word_input = word_input.cuda()\n",
    "\n",
    "encoder_outputs, encoder_hidden = encoder_test(word_input, encoder_hidden)\n",
    "\n",
    "# (batch_size, seq_length, hidden_size)\n",
    "encoder_outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecoderRNN(\n",
      "  (embedding): Embedding(10, 20)\n",
      "  (lstm): LSTM(20, 20, num_layers=2, batch_first=True)\n",
      ")\n",
      "torch.Size([1, 1, 20]) torch.Size([2, 1, 20]) torch.Size([2, 1, 20])\n",
      "torch.Size([1, 1, 20]) torch.Size([2, 1, 20]) torch.Size([2, 1, 20])\n",
      "torch.Size([1, 1, 20]) torch.Size([2, 1, 20]) torch.Size([2, 1, 20])\n"
     ]
    }
   ],
   "source": [
    "decoder_test = DecoderRNN(10, 20, 2)\n",
    "print(decoder_test)\n",
    "\n",
    "word_inputs = torch.LongTensor([[1, 2, 3]])\n",
    "\n",
    "decoder_hidden_h = encoder_hidden[0].reshape(2, 1, 20)\n",
    "decoder_hidden_c = encoder_hidden[1].reshape(2, 1, 20)\n",
    "\n",
    "if USE_CUDA:\n",
    "    decoder_test.cuda()\n",
    "    word_inputs = word_inputs.cuda()\n",
    "\n",
    "for i in range(3):\n",
    "    input = word_inputs[:, i]\n",
    "    decoder_output, decoder_hidden = decoder_test(input, (decoder_hidden_h, decoder_hidden_c))\n",
    "    decoder_hidden_h, decoder_hidden_c = decoder_hidden\n",
    "    print(decoder_output.size(), decoder_hidden_h.size(), decoder_hidden_c.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Seq2seq(nn.Module):\n",
    "    def __init__(self, input_vocab_size, output_vocab_size, hidden_size, n_layers):\n",
    "        super(Seq2seq, self).__init__()\n",
    "        \n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.encoder = EncoderRNN(input_vocab_size, int(hidden_size/2), self.n_layers)\n",
    "        self.decoder = DecoderRNN(output_vocab_size, hidden_size, self.n_layers)\n",
    "        \n",
    "        self.W = nn.Linear(hidden_size, output_vocab_size)\n",
    "        self.softmax = nn.Softmax()\n",
    "        \n",
    "    def forward_encoder(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        init_hidden = self.encoder.init_hidden(batch_size)\n",
    "        encoder_outputs, encoder_hidden = self.encoder(x, init_hidden)\n",
    "        encoder_hidden_h, encoder_hidden_c = encoder_hidden\n",
    "        \n",
    "        decoder_hidden_h = encoder_hidden_h.reshape(self.n_layers, batch_size, self.hidden_size)\n",
    "        decoder_hidden_c = encoder_hidden_c.reshape(self.n_layers, batch_size, self.hidden_size)\n",
    "        return decoder_hidden_h, decoder_hidden_c\n",
    "    \n",
    "    def forward_train(self, x, y):\n",
    "        decoder_hidden_h, decoder_hidden_c = self.forward_encoder(x)\n",
    "        \n",
    "        H = []\n",
    "        for i in range(y.shape[1]):\n",
    "            input = y[:, i]\n",
    "            decoder_output, decoder_hidden = self.decoder(input, (decoder_hidden_h, decoder_hidden_c))\n",
    "            decoder_hidden_h, decoder_hidden_c = decoder_hidden\n",
    "            # h: (batch_size, vocab_size)\n",
    "            h = self.W(decoder_output.squeeze(1))\n",
    "            # h: (batch_size, vocab_size, 1)\n",
    "            H.append(h.unsqueeze(2))\n",
    "        \n",
    "        # H: (batch_size, vocab_size, seq_len)\n",
    "        return torch.cat(H, dim=2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        decoder_hidden_h, decoder_hidden_c = self.forward_encoder(x)\n",
    "        \n",
    "        current_y = SOS_token\n",
    "        result = [current_y]\n",
    "        counter = 0\n",
    "        while current_y != EOS_token and counter < 100:\n",
    "            input = torch.tensor([current_y])\n",
    "            decoder_output, decoder_hidden = self.decoder(input, (decoder_hidden_h, decoder_hidden_c))\n",
    "            decoder_hidden_h, decoder_hidden_c = decoder_hidden\n",
    "            # h: (vocab_size)\n",
    "            h = self.W(decoder_output.squeeze(1)).squeeze(0)\n",
    "            y = self.softmax(h)\n",
    "            _, current_y = torch.max(y, dim=0)\n",
    "            current_y = current_y.item()\n",
    "            result.append(current_y)\n",
    "            counter += 1\n",
    "            \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "model = Seq2seq(source_vocab.n_words, target_vocab.n_words, 300, 2)\n",
    "optim = Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# shuffle training indices\n",
    "assert x.shape[0] == y.shape[0]\n",
    "batch_indices = torch.randperm(x.shape[0])\n",
    "# prepare minibatch generator\n",
    "def batch_generator(batch_indices, batch_size):\n",
    "    batches = math.ceil(len(batch_indices)/batch_size)\n",
    "    for i in range(batches):\n",
    "        batch_start = i*batch_size\n",
    "        batch_end = (i+1)*batch_size\n",
    "        if batch_end > len(batch_indices):\n",
    "            yield batch_indices[batch_start:]\n",
    "        else:\n",
    "            yield batch_indices[batch_start:batch_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34cfb7232e8e4861b81dac7760633ab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-1037:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/anatolii.stehnii/anaconda3/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/anatolii.stehnii/anaconda3/lib/python3.6/site-packages/tqdm/_tqdm.py\", line 144, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/Users/anatolii.stehnii/anaconda3/lib/python3.6/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 training finished, loss: 2.569804273545742\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "867a79b0949747d38e10688409aa5487",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-368-727d33990329>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     87\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     88\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 100\n",
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "nll = nn.NLLLoss()\n",
    "softmax = nn.Softmax(dim=1)\n",
    "\n",
    "# training_dist = torch.zeros(target_vocab.n_words, MAX_SEQ_LENGTH)\n",
    "total_batches = int(len(batch_indices)/BATCH_SIZE)\n",
    "for epoch in range(100):\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(batch_generator(batch_indices, BATCH_SIZE), \n",
    "                      desc='Training epoch {}'.format(epoch+1), \n",
    "                      total=total_batches):\n",
    "        x_train = x[batch, :] \n",
    "        # Here is the fix\n",
    "        y_train = y[batch, :-1] \n",
    "        y_true = y[batch, 1:]\n",
    "        # (batch_size, vocab_size, seq_length)\n",
    "        H = model.forward_train(x_train, y_train)\n",
    "        loss = cross_entropy(H, y_true)\n",
    "#         H = softmax(H)\n",
    "#         likelihood = torch.gather(H, 1, y_true.unsqueeze(1))\n",
    "#         print(target_vocab.unindex_words(y_true[0].numpy()))\n",
    "#         print(likelihood[0])\n",
    "#         break\n",
    "#         loss = torch.neg(torch.sum(torch.log(likelihood)))\n",
    "        assert loss.item() > 0\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        total_loss += loss.item() #/(BATCH_SIZE*MAX_SEQ_LENGTH)\n",
    "    \n",
    "    print('Epoch {} training finished, loss: {}'.format(epoch+1, total_loss/total_batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SOS гора вкрита снігом . EOS PAD PAD PAD PAD'"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 19\n",
    "source_vocab.unindex_words(x[idx].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SOS der berg ist mit schnee bedeckt . EOS PAD'"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_vocab.unindex_words(y[idx].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anatolii.stehnii/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:52: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "y_0_gen = model(x[idx].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SOS ich habe einen buch . EOS'"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_vocab.unindex_words(y_0_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
